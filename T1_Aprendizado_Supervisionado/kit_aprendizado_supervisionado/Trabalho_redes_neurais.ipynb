{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Imports e definição do dataset."
   ],
   "metadata": {
    "id": "8g5GN3EpDn4b"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gpxhsZya71hk",
    "ExecuteTime": {
     "end_time": "2024-10-30T17:40:40.623284Z",
     "start_time": "2024-10-30T17:40:40.618612Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carregamento do dataset cifar-10"
   ],
   "metadata": {
    "id": "qQhkJUZODtd1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Carregar o conjunto de dados CIFAR-10\n",
    "cifar10 = keras.datasets.cifar10\n",
    "#Carrega duas tuplas, representando os dados de treinamento e de teste.\n",
    "#Cada tupla tem as imagens e os respectivos rótulos\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "num_classes = 10"
   ],
   "metadata": {
    "id": "vQQvrT5v785X",
    "ExecuteTime": {
     "end_time": "2024-10-30T17:40:43.120187Z",
     "start_time": "2024-10-30T17:40:40.638293Z"
    }
   },
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": "O código abaixo mostra as 10 primeiras imagens de treino e teste do cifar-10",
   "metadata": {
    "id": "MwHzFJajDxZt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Defina as classes do CIFAR-10\n",
    "class_names = ['Avião', 'Automóvel', 'Pássaro', 'Gato', 'Cervo',\n",
    "               'Cachorro', 'Sapo', 'Cavalo', 'Navio', 'Caminhão']\n",
    "\n",
    "# Crie um dicionário para mapear as classes para as imagens correspondentes\n",
    "class_to_image = {}\n",
    "for i in range(10):\n",
    "    index = (test_labels == i).nonzero()[0][0]  # Encontre o primeiro índice da classe\n",
    "    class_to_image[i] = test_images[index]\n",
    "\n",
    "# Mostre uma imagem de cada classe\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.xticks([])  # Remova os rótulos do eixo x\n",
    "    plt.yticks([])  # Remova os rótulos do eixo y\n",
    "    plt.imshow(class_to_image[i])\n",
    "    plt.xlabel(class_names[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "wJipJNqX9zsJ",
    "outputId": "91ceee79-6051-455e-9cfc-9b2c74390a33",
    "ExecuteTime": {
     "end_time": "2024-11-06T18:41:43.902322Z",
     "start_time": "2024-11-06T18:41:43.456601Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m class_to_image \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m----> 8\u001B[0m     index \u001B[38;5;241m=\u001B[39m (\u001B[43mtest_labels\u001B[49m \u001B[38;5;241m==\u001B[39m i)\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# Encontre o primeiro índice da classe\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     class_to_image[i] \u001B[38;5;241m=\u001B[39m test_images[index]\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Mostre uma imagem de cada classe\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo, convertemos os rótulos escalares (números de 0 a 9) para one-hot encoding.\n",
    "\n",
    "Não é necessário realizar este passo, caso seja utilizada a função de custo esparse_categorical_cross_entropy"
   ],
   "metadata": {
    "id": "hZxLXNIaD4lq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Converter para codificação one-hot dos labels\n",
    "# Classe1 = [1, 0, 0,...]; Classe2 = [0, 1, 0,...]\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
    "#Não é necessário se utilizar como função de custo esparse_categorical_cross_entropy"
   ],
   "metadata": {
    "id": "0h1CJgPJ9MTt",
    "ExecuteTime": {
     "end_time": "2024-10-30T17:40:43.655045Z",
     "start_time": "2024-10-30T17:40:43.614288Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 19 is out of bounds for axis 1 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Converter para codificação one-hot dos labels\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# Classe1 = [1, 0, 0,...]; Classe2 = [0, 1, 0,...]\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m train_labels \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_categorical\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_classes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m test_labels \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mto_categorical(test_labels, num_classes\u001B[38;5;241m=\u001B[39mnum_classes)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m#Não é necessário se utilizar como função de custo esparse_categorical_cross_entropy\u001B[39;00m\n",
      "File \u001B[1;32m~\\venv\\Lib\\site-packages\\keras\\src\\utils\\numerical_utils.py:99\u001B[0m, in \u001B[0;36mto_categorical\u001B[1;34m(x, num_classes)\u001B[0m\n\u001B[0;32m     97\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     98\u001B[0m categorical \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((batch_size, num_classes))\n\u001B[1;32m---> 99\u001B[0m \u001B[43mcategorical\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marange\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    100\u001B[0m output_shape \u001B[38;5;241m=\u001B[39m input_shape \u001B[38;5;241m+\u001B[39m (num_classes,)\n\u001B[0;32m    101\u001B[0m categorical \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mreshape(categorical, output_shape)\n",
      "\u001B[1;31mIndexError\u001B[0m: index 19 is out of bounds for axis 1 with size 10"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "Função que retorna uma rede neural para o cifar-10"
   ],
   "metadata": {
    "id": "nymnOpRMETAu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Crie o modelo de rede neural convolucional simples\n",
    "def get_cifar10_network():\n",
    "    # Atributos\n",
    "    # Camada convolucional:\n",
    "    num_filtros = 32\n",
    "    tam_filtro = 3\n",
    "    x_stride = 1\n",
    "    y_stride = 1\n",
    "    \n",
    "    # Max Pooling:\n",
    "    tam_pooling = 2\n",
    "    \n",
    "    # Neurônios na 1º camada\n",
    "    neurons_fst_layer = 64\n",
    "    \n",
    "    # Testar    \n",
    "    # - stride igual ao tamanho do filtro (sem overlap) \n",
    "    # - stride maior que o tamanho do filtro (overlap)\n",
    "    # - maior tamanho da \"área\" de pooling (menos informação)\n",
    "    # - maior / menor número de neurônios\n",
    "    # - maior número de camadas\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # Camada convolucional 32 filtros 3x3. \n",
    "        # Podemos mudar quantidade de filtros, tamanho do filtro é geralmente 3x3, o \"stride\" pode ser aumentado para agilizar a execução.\n",
    "        tf.keras.layers.Conv2D(num_filtros, (tam_filtro, tam_filtro), strides=(x_stride, y_stride), activation='relu', input_shape=(32, 32, 3)),\n",
    "        #(32, 32, 3) porque as imagens são 32X32 e RGB, portanto, tendo 3 canais de cor\n",
    "        \n",
    "        # Max Pooling 2x2. \n",
    "        # Podemos aumentar tamanho para agilizar execução, mas perdemos precisão.\n",
    "        tf.keras.layers.MaxPooling2D((tam_pooling, tam_pooling)),\n",
    "        \n",
    "        # Transforma matriz de pesos em vetor.\n",
    "        tf.keras.layers.Flatten(),\n",
    "        \n",
    "        # Camada de entrada com unção de ativação Relu.\n",
    "        # Pode mudar o número de neurônios por camada ou adicionar camadas.\n",
    "        tf.keras.layers.Dense(neurons_fst_layer, activation='relu'),\n",
    "        # Camada com 10 neurônios de saída representativos das classes.\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')  # 10 classes de saída\n",
    "    ])\n",
    "\n",
    "    # Compile o modelo\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',#pode ser substituída pela esparse_categorical_cross_entropy\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "id": "nPrIRBmT8XiN"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Trecho para treinar e avaliar a rede neural.\n",
    "O treino é realizado com os dados de treino e a avaliação do modelo é realizada nos dados de teste."
   ],
   "metadata": {
    "id": "wjmscwcQErIx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Treine o modelo\n",
    "model = get_cifar10_network()\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# Avalie o modelo no conjunto de teste\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uN8v8_m8cvR",
    "outputId": "8fc65d80-77bf-4d3f-aa99-14cd9713ac0f",
    "ExecuteTime": {
     "end_time": "2024-10-30T17:18:05.927536Z",
     "start_time": "2024-10-30T17:18:04.615855Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_cifar10_network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Treine o modelo\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mget_cifar10_network\u001B[49m()\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(train_images, train_labels, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Avalie o modelo no conjunto de teste\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'get_cifar10_network' is not defined"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na célula abaixo, adicione o código para carregar os demais datasets"
   ],
   "metadata": {
    "id": "Vc5-m031HdY0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Inclua o código para carregar os demais datasets"
   ],
   "metadata": {
    "id": "9l2VipoMHnmH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tarefa\n",
    "Escreva código para executar redes neurais nos seguintes datasets:\n",
    "\n",
    "MNIST (pode aproveitar o codigo existente)\n",
    "Fashion MNIST\n",
    "CIFAR-10\n",
    "CIFAR-100\n",
    "Cada execução deve ser por 10 épocas.\n",
    "\n",
    "Você deve preencher as funções a seguir para retornarem a rede neural com a melhor configuração que você conseguiu para cada dataset. O notebook deve ser entregue com a rede neural que obteve a melhor performance em cada conjunto de dados.\n",
    "\n",
    "IMPORTANTE: as funções não devem TREINAR nem AVALIAR as redes neurais, apenas instanciá-las e retorná-las.\n",
    "\n",
    "Ao final, preencha o dict results com o desempenho encontrado em cada execução."
   ],
   "metadata": {
    "id": "bKkBlEy1ExHj"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_fashion_mnist_network():\n",
    "    num_filtros = 16\n",
    "    dim_filtro = 3\n",
    "\n",
    "    # Max Pooling:\n",
    "    dim_mat_max_pooling = 2\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(num_filtros, (dim_filtro, dim_filtro), activation='relu', input_shape=(28, 28, 1)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(num_filtros * 2, (dim_filtro, dim_filtro), activation='relu', input_shape=(26, 26, 1)),\n",
    "\n",
    "        tf.keras.layers.MaxPool2D((dim_mat_max_pooling, dim_mat_max_pooling),),\n",
    "\n",
    "        tf.keras.layers.Flatten(),  # achatar p/ se ajustar à MLP\n",
    "\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')  # 1 camada de saida com 10 neuronios\n",
    "    ])\n",
    "\n",
    "    model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_mnist_network():\n",
    "    num_filtros = 16\n",
    "    dim_filtro = 3\n",
    "\n",
    "    # Max Pooling:\n",
    "    dim_mat_max_pooling = 2\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(num_filtros, (dim_filtro, dim_filtro), activation='relu', input_shape=(28, 28, 1)),\n",
    "\n",
    "        tf.keras.layers.MaxPool2D((dim_mat_max_pooling, dim_mat_max_pooling),),\n",
    "\n",
    "        tf.keras.layers.Conv2D(num_filtros * 2, (dim_filtro, dim_filtro), activation='relu', input_shape=(26, 26, 1)),\n",
    "        # 1 camada de convolução: 16 filtros 3x3, stride padrão (1,1), ativação relu\n",
    "        tf.keras.layers.MaxPool2D((dim_mat_max_pooling, dim_mat_max_pooling), ),  # max pooling 2x2\n",
    "        tf.keras.layers.Flatten(),  # achatar p/ se ajustar à MLP\n",
    "\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')  # 1 camada de saida com 10 neuronios\n",
    "    ])\n",
    "\n",
    "    model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "'''\n",
    "# Definindo o callback de early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',     # Monitora a perda de validação (val_loss) durante o treino\n",
    "    patience=3,             # Número de épocas sem melhoria antes de parar\n",
    "    restore_best_weights=True  # Restaura os pesos da melhor época\n",
    ")\n",
    "# Treinando o modelo com o early stopping\n",
    "start_time = time.time()\n",
    "model = get_mnist_network()\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=10,\n",
    "    validation_data=(test_images, test_labels),  # Dados de validação\n",
    "    callbacks=[early_stopping]  # Passa o early stopping como callback\n",
    ")\n",
    "end_time = time.time()\n",
    "'''\n",
    "\n",
    "def get_cifar100_network():\n",
    "    # Atributos\n",
    "    # Camada convolucional:\n",
    "    num_filtros = 64\n",
    "    dim_filtro = 3\n",
    "\n",
    "    # Max Pooling:\n",
    "    dim_pooling = 2\n",
    "\n",
    "    # Neurônios na 1º camada da MLP\n",
    "    neurons_in_layer = 64\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        # Camada convolucional (32 filtros 3x3)\n",
    "        # Podemos mudar quantidade de filtros, tamanho do filtro é geralmente 3x3, o \"stride\" pode ser aumentado para agilizar a execução.\n",
    "        tf.keras.layers.Conv2D(num_filtros, (dim_filtro, dim_filtro), strides=(1, 1), activation='relu',\n",
    "                               input_shape=(32, 32, 3)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(num_filtros, (dim_filtro, dim_filtro), strides=(1, 1), activation='relu',\n",
    "                               input_shape=(30, 30, 3)),\n",
    "        #(32, 32, 3) porque as imagens são 32X32 e RGB, portanto, tendo 3 canais de cor\n",
    "\n",
    "        # Max Pooling (2x2)\n",
    "        # Podemos aumentar tamanho para agilizar execução, mas perdemos precisão.\n",
    "        tf.keras.layers.MaxPooling2D((dim_pooling, dim_pooling)),\n",
    "\n",
    "        # Transforma matriz de pesos em vetor.\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        # MLP (Porção totalmente conexa)\n",
    "        # Camada neurônios função de ativação Relu.\n",
    "        tf.keras.layers.Dense(neurons_in_layer, activation='relu'),\n",
    "        # Camada com 10 neurônios de saída representativos das classes.\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')  # 10 classes de saída\n",
    "    ])\n",
    "\n",
    "    # Compile o modelo\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',  #pode ser substituída pela esparse_categorical_cross_entropy\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "#Você pode aproveitar as ideias do exemplo acima\n",
    "def get_cifar10_network():\n",
    "    # Atributos\n",
    "    # Camada convolucional:\n",
    "    num_filtros = 32\n",
    "    tam_filtro = 3\n",
    "\n",
    "    # Max Pooling:\n",
    "    tam_pooling = 2\n",
    "\n",
    "    # Neurônios na 1º camada\n",
    "    neurons_in_layer = 64\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        # Camada convolucional (32 filtros 3x3)\n",
    "        # Podemos mudar quantidade de filtros, tamanho do filtro é geralmente 3x3, o \"stride\" pode ser aumentado para agilizar a execução.\n",
    "        tf.keras.layers.Conv2D(num_filtros, (tam_filtro, tam_filtro), strides=(1, 1), activation='relu',\n",
    "                               input_shape=(32, 32, 3)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(num_filtros, (tam_filtro, tam_filtro), strides=(1, 1), activation='relu',\n",
    "                               input_shape=(30, 30, 3)),\n",
    "        #(32, 32, 3) porque as imagens são 32X32 e RGB, portanto, tendo 3 canais de cor\n",
    "\n",
    "        # Max Pooling (2x2)\n",
    "        # Podemos aumentar tamanho para agilizar execução, mas perdemos precisão.\n",
    "        tf.keras.layers.MaxPooling2D((tam_pooling, tam_pooling)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(num_filtros, (tam_filtro, tam_filtro), strides=(1, 1), activation='relu',\n",
    "                               input_shape=(14, 14, 3)),\n",
    "\n",
    "        tf.keras.layers.MaxPooling2D((tam_pooling, tam_pooling)),\n",
    "\n",
    "        # Transforma matriz de pesos em vetor.\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        # MLP (Porção totalmente conexa)\n",
    "        # Camada neurônios função de ativação Relu.\n",
    "        tf.keras.layers.Dense(neurons_in_layer, activation='relu'),\n",
    "        # Camada com 10 neurônios de saída representativos das classes.\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')  # 10 classes de saída\n",
    "    ])\n",
    "\n",
    "    # Compile o modelo\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',  #pode ser substituída pela esparse_categorical_cross_entropy\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preencha o dict abaixo substituindo os None com a acuracia final (acc) e o tempo de treinamento (time) encontrado no seu experimento pra cada dataset"
   ],
   "metadata": {
    "id": "iERVafMPF2Tn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results = {\n",
    "    \"mnist\": {\"time\": None, \"acc\": None},\n",
    "    \"fashion_mnist\": {\"time\": None, \"acc\": None},\n",
    "    \"cifar10\": {\"time\": None, \"acc\": None},\n",
    "    \"cifar100\": {\"time\": None, \"acc\": None},\n",
    "}"
   ],
   "metadata": {
    "id": "kEUK1xk6Fk48"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
